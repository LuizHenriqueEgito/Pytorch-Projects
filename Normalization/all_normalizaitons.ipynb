{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7651a466-2aea-47e6-98e5-59d55f46ebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57797cd7-29f7-4042-abcc-a548102dc5fb",
   "metadata": {},
   "source": [
    "# Batch norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "071afe17-b5d4-4b09-bd9a-aca905b04369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.],\n",
      "        [7., 8.]], dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "# Criando 1 batch, 4 linhas, 2 colunas\n",
    "tensor = torch.tensor([[1, 2],\n",
    "                       [3, 4],\n",
    "                       [5, 6],\n",
    "                       [7, 8]], dtype=torch.bfloat16)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7cb33a3-8fe5-4168-b80b-845656e104ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96c579ec-1801-499e-8cf5-36917eeb3ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atenção você não pode ter a dim do batch só das linhas, colunas\n",
    "batch_norm = nn.BatchNorm1d(num_features=2, affine=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b504eeab-b740-45f5-ac25-257d77680a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3438, -1.3438],\n",
      "        [-0.4473, -0.4473],\n",
      "        [ 0.4473,  0.4473],\n",
      "        [ 1.3438,  1.3438]], dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "batchnorm_tensor = batch_norm(tensor)\n",
    "print(batchnorm_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5796966-7ca6-42f2-9cf2-55886bef68cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Batch:\n",
      "tensor([[4., 5.]], dtype=torch.bfloat16)\n",
      "Var Batch:\n",
      "tensor([[5., 5.]], dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "# Calculando a média e a variância do lote\n",
    "mean_batch = tensor.mean(dim=0, keepdim=True)\n",
    "var_batch = tensor.var(dim=0, keepdim=True, unbiased=False)\n",
    "print(f'Mean Batch:\\n{mean_batch}')\n",
    "print(f'Var Batch:\\n{var_batch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bed48b5c-68c6-4a41-b87d-a23752802d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3438, -1.3438],\n",
      "        [-0.4473, -0.4473],\n",
      "        [ 0.4473,  0.4473],\n",
      "        [ 1.3438,  1.3438]], dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "# Aplicando a normalização em lote manualmente\n",
    "manual_batchnorm = (tensor - mean_batch) / torch.sqrt(var_batch)\n",
    "print(manual_batchnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d88dff39-3d77-4735-8fc5-8577b10b2f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True],\n",
       "        [True, True],\n",
       "        [True, True],\n",
       "        [True, True]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_batchnorm == batchnorm_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb22725a-9364-4f87-a901-8fef9cd42694",
   "metadata": {},
   "source": [
    "# Layer Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ca7491c-b426-4d74-978b-86c6f4160804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemplo com imagem (B, C, H, W): (2, 3, 2, 2)\n",
    "# 1º batch\n",
    "tensor = torch.tensor([[[[1, 2],  # 1º canal 1º batch\n",
    "                          [0, 0]],\n",
    "\n",
    "                         [[0, 1],  # 2º canal 1º batch\n",
    "                          [0, 0]],\n",
    "                \n",
    "                         [[2, 1],  # 3º canal 1º batch\n",
    "                          [1, 1]]],\n",
    "\n",
    "# 2º batch\n",
    "                        [[[2, 0],  # 1º canal 2º batch\n",
    "                          [1, 1]],\n",
    "\n",
    "                         [[2, 0],  # 2º canal 2º batch\n",
    "                          [2, 2]],\n",
    "\n",
    "                         [[1, 2],  # 3º canal 2º batch\n",
    "                          [2, 2]]]], dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d72d7d1b-b85b-4c17-8bd7-95754e2bdc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5469a6fe-fcae-4a20-818b-7fb62473683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# como eu quero normalizar por canal eu coloco normalized_shape=(3, 2, 2) Pois eu não estou olhando para o Batch por isso eu removo o 2,\n",
    "layer_norm = nn.LayerNorm(normalized_shape=(3, 2, 2), elementwise_affine=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ae2dc253-b5b4-4c56-bbea-d161eb4cff4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "layernorm_tensor = layer_norm(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1dbed027-cb0e-4dd9-b14c-914ce9cc6f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.7500]]],\n",
      "\n",
      "\n",
      "        [[[1.4141]]]], dtype=torch.bfloat16)\n",
      "tensor([[[[0.5195]]],\n",
      "\n",
      "\n",
      "        [[[0.5781]]]], dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "# removo a dim do batch por isso não coloco o 0\n",
    "mean_layer = tensor.mean(dim=(1, 2, 3), keepdim=True)\n",
    "print(mean_layer)\n",
    "var_layer = tensor.var(dim=(1, 2, 3), keepdim=True, unbiased=False)\n",
    "print(var_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a5e47492-f24c-4c9b-aa8c-684f7ff8176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizando manualmente\n",
    "manual_batchnorm = (tensor - mean_layer) / torch.sqrt(var_layer + layer_norm.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0d6e86cf-3cc8-401c-b252-86533c22d551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manualmente:\n",
      "tensor([[[[ 0.3457,  1.7266],\n",
      "          [-1.0391, -1.0391]],\n",
      "\n",
      "         [[-1.0391,  0.3457],\n",
      "          [-1.0391, -1.0391]],\n",
      "\n",
      "         [[ 1.7266,  0.3457],\n",
      "          [ 0.3457,  0.3457]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7695, -1.8594],\n",
      "          [-0.5430, -0.5430]],\n",
      "\n",
      "         [[ 0.7695, -1.8594],\n",
      "          [ 0.7695,  0.7695]],\n",
      "\n",
      "         [[-0.5430,  0.7695],\n",
      "          [ 0.7695,  0.7695]]]], dtype=torch.bfloat16)\n",
      "\n",
      "Usando LayerNorm:\n",
      "tensor([[[[ 0.3457,  1.7344],\n",
      "          [-1.0391, -1.0391]],\n",
      "\n",
      "         [[-1.0391,  0.3457],\n",
      "          [-1.0391, -1.0391]],\n",
      "\n",
      "         [[ 1.7344,  0.3457],\n",
      "          [ 0.3457,  0.3457]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7695, -1.8672],\n",
      "          [-0.5469, -0.5469]],\n",
      "\n",
      "         [[ 0.7695, -1.8672],\n",
      "          [ 0.7695,  0.7695]],\n",
      "\n",
      "         [[-0.5469,  0.7695],\n",
      "          [ 0.7695,  0.7695]]]], dtype=torch.bfloat16)\n",
      "\n",
      "Elas estão muito proximas mas não são identicas, porque?\n"
     ]
    }
   ],
   "source": [
    "print(f'Manualmente:\\n{manual_batchnorm}')\n",
    "print(f'\\nUsando LayerNorm:\\n{layernorm_tensor}')\n",
    "print('\\nElas estão muito proximas mas não são identicas, porque?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a0515852-e4b6-4abe-804d-f81d8ac675ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo com texto ()\n",
    "# 2: sequencias, 3: tokens, 5: embeddings\n",
    "X = torch.randint(0, 10, (2, 3, 5), dtype=torch.bfloat16)\n",
    "normalized_shape = (5,)  # normalização feita na dimensão do embedding\n",
    "layer_norm = nn.LayerNorm(normalized_shape=normalized_shape, elementwise_affine=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "24e6a5b1-5c15-482b-8006-2d5821fb209e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2., 4., 4., 0., 2.],\n",
       "         [6., 2., 9., 9., 4.],\n",
       "         [1., 5., 0., 5., 1.]],\n",
       "\n",
       "        [[3., 6., 9., 7., 1.],\n",
       "         [6., 5., 9., 1., 5.],\n",
       "         [6., 6., 8., 2., 6.]]], dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "88d38a80-5223-4014-8bfd-752b2db17168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2676,  1.0703,  1.0703, -1.6016, -0.2676],\n",
       "         [ 0.0000, -1.4531,  1.0859,  1.0859, -0.7266],\n",
       "         [-0.6484,  1.2031, -1.1172,  1.2031, -0.6484]],\n",
       "\n",
       "        [[-0.7695,  0.2793,  1.3281,  0.6289, -1.4688],\n",
       "         [ 0.3125, -0.0781,  1.4844, -1.6406, -0.0781],\n",
       "         [ 0.2041,  0.2041,  1.2266, -1.8359,  0.2041]]], dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_norm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "544c26fa-2506-4f37-826c-0aff6f5151a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provando manualmente\n",
    "mean_layer = X.mean(dim=2, keepdims=True)\n",
    "var_layer = X.var(dim=2, keepdims=True, unbiased=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "77a8f789-372f-4d69-acd3-d2bd3621d93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_layer = (X - mean_layer) / torch.sqrt(var_layer + layer_norm.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bb416041-6046-4cd9-8d20-577bdf77156a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2715,  1.0703,  1.0703, -1.6094, -0.2715],\n",
       "         [ 0.0000, -1.4531,  1.0938,  1.0938, -0.7266],\n",
       "         [-0.6523,  1.2031, -1.1172,  1.2031, -0.6523]],\n",
       "\n",
       "        [[-0.7656,  0.2832,  1.3359,  0.6328, -1.4609],\n",
       "         [ 0.3164, -0.0732,  1.4844, -1.6328, -0.0732],\n",
       "         [ 0.2070,  0.2070,  1.2266, -1.8359,  0.2070]]], dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# novamente chega muito proximo mas não bate nas casas decimais\n",
    "manual_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3408419-20d1-42e6-93dc-7f717a5f28dc",
   "metadata": {},
   "source": [
    "Em outras palavras, se você está operando em um tensor tridimensional, como no seu caso onde cada \"matriz\" representa uma frase e cada linha é um token com seu embedding, o normalized_shape deve ser um tuple que corresponde ao número de dimensões que você deseja normalizar.\r\n",
    "\r\n",
    "Por exemplo, se você tem um tensor com shape (batch_size, sequence_length, embedding_size), e deseja normalizar ao longo das dimensões dos embeddings (ou seja, ao longo da dimensão do embedding_size), você deve definir normalized_shape como (embedding_size,).\r\n",
    "\r\n",
    "Se você deseja normalizar ao longo de todas as dimensões, você pode simplesmente definir normalized_shape como o número total de dimensões no tensor.\r\n",
    "\r\n",
    "No seu caso específico, onde cada \"matriz\" representa uma frase e cada linha é um token com seu embedding, o normalized_shape deve ser (num_columns,), onde num_columns é o número de colunas em cada \"matriz\" (ou seja, o número de dimensões dos embeddings)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab34d6e-9517-4201-b277-9d85da5a86cc",
   "metadata": {},
   "source": [
    "# Instance Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "b5f04e5f-1de8-4305-8967-f527c5e586d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemplo com imagem (B, C, H, W): (2, 3, 2, 2)\n",
    "# 1º batch\n",
    "tensor = torch.tensor([[[[1, 2],  # 1º canal 1º batch\n",
    "                          [0, 0]],\n",
    "\n",
    "                         [[0, 1],  # 2º canal 1º batch\n",
    "                          [0, 0]],\n",
    "                \n",
    "                         [[2, 1],  # 3º canal 1º batch\n",
    "                          [1, 1]]],\n",
    "\n",
    "# 2º batch\n",
    "                        [[[2, 0],  # 1º canal 2º batch\n",
    "                          [1, 1]],\n",
    "\n",
    "                         [[2, 0],  # 2º canal 2º batch\n",
    "                          [2, 2]],\n",
    "\n",
    "                         [[1, 2],  # 3º canal 2º batch\n",
    "                          [2, 2]]]], dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0263a38a-8f32-4d7b-bce8-2f4bdfe4b1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_features: nº de canais nesse caso 3\n",
    "instance_norm = nn.InstanceNorm2d(num_features=3, affine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f36f2e46-eccc-4a35-a41e-a57dfbde2149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.3008,  1.5078],\n",
       "          [-0.9062, -0.9062]],\n",
       "\n",
       "         [[-0.5781,  1.7344],\n",
       "          [-0.5781, -0.5781]],\n",
       "\n",
       "         [[ 1.7344, -0.5781],\n",
       "          [-0.5781, -0.5781]]],\n",
       "\n",
       "\n",
       "        [[[ 1.4141, -1.4141],\n",
       "          [ 0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.5781, -1.7344],\n",
       "          [ 0.5781,  0.5781]],\n",
       "\n",
       "         [[-1.7344,  0.5781],\n",
       "          [ 0.5781,  0.5781]]]], dtype=torch.bfloat16, grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_norm(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dafe22b-e4ae-452b-babd-b8b9b71a4261",
   "metadata": {},
   "source": [
    "# Group Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "260be0e9-425d-42dd-87fe-a04a47dd84cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemplo com imagem (B, C, H, W): (2, 3, 2, 2)\n",
    "# 1º batch\n",
    "tensor = torch.randint(0, 4, (2, 8, 2, 2), dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0b8a70e0-5db0-42d8-a80d-b16ff83e2c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 3.],\n",
       "          [0., 1.]],\n",
       "\n",
       "         [[0., 0.],\n",
       "          [2., 3.]],\n",
       "\n",
       "         [[1., 2.],\n",
       "          [3., 1.]],\n",
       "\n",
       "         [[0., 1.],\n",
       "          [1., 1.]],\n",
       "\n",
       "         [[0., 3.],\n",
       "          [1., 0.]],\n",
       "\n",
       "         [[3., 2.],\n",
       "          [1., 2.]],\n",
       "\n",
       "         [[3., 3.],\n",
       "          [0., 3.]],\n",
       "\n",
       "         [[3., 3.],\n",
       "          [2., 2.]]],\n",
       "\n",
       "\n",
       "        [[[0., 3.],\n",
       "          [3., 1.]],\n",
       "\n",
       "         [[3., 1.],\n",
       "          [2., 0.]],\n",
       "\n",
       "         [[2., 2.],\n",
       "          [2., 2.]],\n",
       "\n",
       "         [[2., 1.],\n",
       "          [1., 1.]],\n",
       "\n",
       "         [[3., 0.],\n",
       "          [0., 2.]],\n",
       "\n",
       "         [[2., 1.],\n",
       "          [3., 2.]],\n",
       "\n",
       "         [[0., 1.],\n",
       "          [2., 2.]],\n",
       "\n",
       "         [[3., 1.],\n",
       "          [3., 0.]]]], dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fcbe49e9-9061-4a8a-bfd5-2824c9b66b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.1094,  1.6875],\n",
       "          [-1.1094, -0.1748]],\n",
       "\n",
       "         [[-1.1094, -1.1094],\n",
       "          [ 0.7578,  1.6875]],\n",
       "\n",
       "         [[-0.1748,  0.7578],\n",
       "          [ 1.6875, -0.1748]],\n",
       "\n",
       "         [[-1.1094, -0.1748],\n",
       "          [-0.1748, -0.1748]],\n",
       "\n",
       "         [[-1.6953,  0.9297],\n",
       "          [-0.8203, -1.6953]],\n",
       "\n",
       "         [[ 0.9297,  0.0547],\n",
       "          [-0.8203,  0.0547]],\n",
       "\n",
       "         [[ 0.9297,  0.9297],\n",
       "          [-1.6953,  0.9297]],\n",
       "\n",
       "         [[ 0.9297,  0.9297],\n",
       "          [ 0.0547,  0.0547]]],\n",
       "\n",
       "\n",
       "        [[[-1.7500,  1.4844],\n",
       "          [ 1.4844, -0.6758]],\n",
       "\n",
       "         [[ 1.4844, -0.6758],\n",
       "          [ 0.4043, -1.7500]],\n",
       "\n",
       "         [[ 0.4043,  0.4043],\n",
       "          [ 0.4043,  0.4043]],\n",
       "\n",
       "         [[ 0.4043, -0.6758],\n",
       "          [-0.6758, -0.6758]],\n",
       "\n",
       "         [[ 1.2891, -1.3984],\n",
       "          [-1.3984,  0.3926]],\n",
       "\n",
       "         [[ 0.3926, -0.5039],\n",
       "          [ 1.2891,  0.3926]],\n",
       "\n",
       "         [[-1.3984, -0.5039],\n",
       "          [ 0.3926,  0.3926]],\n",
       "\n",
       "         [[ 1.2891, -0.5039],\n",
       "          [ 1.2891, -1.3984]]]], dtype=torch.bfloat16,\n",
       "       grad_fn=<NativeGroupNormBackward0>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separando 8 canais em 2 grupos\n",
    "group_norm = nn.GroupNorm(num_groups=2, num_channels=8)\n",
    "group_norm(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8f31bf9e-425b-405d-b4b7-f12598894a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.8164,  1.6328],\n",
       "          [-0.8164,  0.0000]],\n",
       "\n",
       "         [[-0.9609, -0.9609],\n",
       "          [ 0.5781,  1.3438]],\n",
       "\n",
       "         [[-0.9062,  0.3008],\n",
       "          [ 1.5078, -0.9062]],\n",
       "\n",
       "         [[-1.7344,  0.5781],\n",
       "          [ 0.5781,  0.5781]],\n",
       "\n",
       "         [[-0.8164,  1.6328],\n",
       "          [ 0.0000, -0.8164]],\n",
       "\n",
       "         [[ 1.4141,  0.0000],\n",
       "          [-1.4141,  0.0000]],\n",
       "\n",
       "         [[ 0.5781,  0.5781],\n",
       "          [-1.7344,  0.5781]],\n",
       "\n",
       "         [[ 1.0000,  1.0000],\n",
       "          [-1.0000, -1.0000]]],\n",
       "\n",
       "\n",
       "        [[[-1.3438,  0.9609],\n",
       "          [ 0.9609, -0.5781]],\n",
       "\n",
       "         [[ 1.3438, -0.4473],\n",
       "          [ 0.4473, -1.3438]],\n",
       "\n",
       "         [[ 0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000]],\n",
       "\n",
       "         [[ 1.7344, -0.5781],\n",
       "          [-0.5781, -0.5781]],\n",
       "\n",
       "         [[ 1.3438, -0.9609],\n",
       "          [-0.9609,  0.5781]],\n",
       "\n",
       "         [[ 0.0000, -1.4141],\n",
       "          [ 1.4141,  0.0000]],\n",
       "\n",
       "         [[-1.5078, -0.3008],\n",
       "          [ 0.9062,  0.9062]],\n",
       "\n",
       "         [[ 0.9609, -0.5781],\n",
       "          [ 0.9609, -1.3438]]]], dtype=torch.bfloat16,\n",
       "       grad_fn=<NativeGroupNormBackward0>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separando 8 canais em 8 grupos (Equivalente ao IntanceNorm)\n",
    "group_norm = nn.GroupNorm(num_groups=8, num_channels=8)\n",
    "group_norm(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bda9cfb9-0d5f-4059-93f9-406a8813f5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ True,  True],\n",
       "          [ True,  True]],\n",
       "\n",
       "         [[ True,  True],\n",
       "          [ True,  True]],\n",
       "\n",
       "         [[False,  True],\n",
       "          [False, False]],\n",
       "\n",
       "         [[ True,  True],\n",
       "          [ True,  True]],\n",
       "\n",
       "         [[ True,  True],\n",
       "          [ True,  True]],\n",
       "\n",
       "         [[ True,  True],\n",
       "          [ True,  True]],\n",
       "\n",
       "         [[ True,  True],\n",
       "          [ True,  True]],\n",
       "\n",
       "         [[ True,  True],\n",
       "          [ True,  True]]],\n",
       "\n",
       "\n",
       "        [[[ True,  True],\n",
       "          [ True,  True]],\n",
       "\n",
       "         [[ True,  True],\n",
       "          [ True,  True]],\n",
       "\n",
       "         [[ True,  True],\n",
       "          [ True,  True]],\n",
       "\n",
       "         [[ True,  True],\n",
       "          [ True,  True]],\n",
       "\n",
       "         [[ True,  True],\n",
       "          [ True,  True]],\n",
       "\n",
       "         [[ True,  True],\n",
       "          [ True,  True]],\n",
       "\n",
       "         [[False,  True],\n",
       "          [False, False]],\n",
       "\n",
       "         [[ True,  True],\n",
       "          [ True,  True]]]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_norm = nn.InstanceNorm2d(num_features=8)\n",
    "instance_norm(tensor) == group_norm(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bbb0dd13-6a6d-4d86-be7e-8dbd23ae6b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.3359,  1.2266],\n",
       "          [-1.3359, -0.4805]],\n",
       "\n",
       "         [[-1.3359, -1.3359],\n",
       "          [ 0.3730,  1.2266]],\n",
       "\n",
       "         [[-0.4805,  0.3730],\n",
       "          [ 1.2266, -0.4805]],\n",
       "\n",
       "         [[-1.3359, -0.4805],\n",
       "          [-0.4805, -0.4805]],\n",
       "\n",
       "         [[-1.3359,  1.2266],\n",
       "          [-0.4805, -1.3359]],\n",
       "\n",
       "         [[ 1.2266,  0.3730],\n",
       "          [-0.4805,  0.3730]],\n",
       "\n",
       "         [[ 1.2266,  1.2266],\n",
       "          [-1.3359,  1.2266]],\n",
       "\n",
       "         [[ 1.2266,  1.2266],\n",
       "          [ 0.3730,  0.3730]]],\n",
       "\n",
       "\n",
       "        [[[-1.5547,  1.3672],\n",
       "          [ 1.3672, -0.5781]],\n",
       "\n",
       "         [[ 1.3672, -0.5781],\n",
       "          [ 0.3965, -1.5547]],\n",
       "\n",
       "         [[ 0.3965,  0.3965],\n",
       "          [ 0.3965,  0.3965]],\n",
       "\n",
       "         [[ 0.3965, -0.5781],\n",
       "          [-0.5781, -0.5781]],\n",
       "\n",
       "         [[ 1.3672, -1.5547],\n",
       "          [-1.5547,  0.3965]],\n",
       "\n",
       "         [[ 0.3965, -0.5781],\n",
       "          [ 1.3672,  0.3965]],\n",
       "\n",
       "         [[-1.5547, -0.5781],\n",
       "          [ 0.3965,  0.3965]],\n",
       "\n",
       "         [[ 1.3672, -0.5781],\n",
       "          [ 1.3672, -1.5547]]]], dtype=torch.bfloat16,\n",
       "       grad_fn=<NativeGroupNormBackward0>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separando 8 canais em 1 grupo (equivalente ao LayerNorm)\n",
    "group_norm = nn.GroupNorm(num_channels=8, num_groups=1)\n",
    "group_norm(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0f813839-707a-4907-bde4-6e1b9e044f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[True, True],\n",
       "          [True, True]],\n",
       "\n",
       "         [[True, True],\n",
       "          [True, True]],\n",
       "\n",
       "         [[True, True],\n",
       "          [True, True]],\n",
       "\n",
       "         [[True, True],\n",
       "          [True, True]],\n",
       "\n",
       "         [[True, True],\n",
       "          [True, True]],\n",
       "\n",
       "         [[True, True],\n",
       "          [True, True]],\n",
       "\n",
       "         [[True, True],\n",
       "          [True, True]],\n",
       "\n",
       "         [[True, True],\n",
       "          [True, True]]],\n",
       "\n",
       "\n",
       "        [[[True, True],\n",
       "          [True, True]],\n",
       "\n",
       "         [[True, True],\n",
       "          [True, True]],\n",
       "\n",
       "         [[True, True],\n",
       "          [True, True]],\n",
       "\n",
       "         [[True, True],\n",
       "          [True, True]],\n",
       "\n",
       "         [[True, True],\n",
       "          [True, True]],\n",
       "\n",
       "         [[True, True],\n",
       "          [True, True]],\n",
       "\n",
       "         [[True, True],\n",
       "          [True, True]],\n",
       "\n",
       "         [[True, True],\n",
       "          [True, True]]]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_norm = nn.LayerNorm(normalized_shape=(8, 2, 2), elementwise_affine=False)\n",
    "layer_norm(tensor) == group_norm(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bf8fa3-3f68-4997-b30e-824e611daa25",
   "metadata": {},
   "source": [
    "# Utilizando nn.functional F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79c6ff3-2fb0-4b3a-a8d1-f54f1e8071f5",
   "metadata": {},
   "source": [
    "Para utilizar o `nn.functional` você irá precisar da media e da variancia do seu tensor:\n",
    "``` python\n",
    "import torch.nn.functional as F\n",
    "F.batch_norm()\n",
    "F.layer_norm()\n",
    "F.instance_norm()\n",
    "F.group_norm()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77235630-ceb1-4f91-bd6b-01356fe5f007",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pytorch",
   "language": "python",
   "name": "env_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
